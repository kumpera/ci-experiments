{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\r\n",
    "from dro import OnlineDRO\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def gen_pmf(actions, epsilon, exploit_idx):\r\n",
    "    pmf = [epsilon / actions] * actions\r\n",
    "    pmf[exploit_idx] += 1 - epsilon\r\n",
    "    return pmf\r\n",
    "\r\n",
    "\r\n",
    "def sample_custom_pmf(pmf):\r\n",
    "    total = sum(pmf)\r\n",
    "    scale = 1 / total\r\n",
    "    pmf = [x * scale for x in pmf]\r\n",
    "    draw = np.random.random()\r\n",
    "    sum_prob = 0.0\r\n",
    "    for index, prob in enumerate(pmf):\r\n",
    "        sum_prob += prob\r\n",
    "        if(sum_prob > draw):\r\n",
    "            return index\r\n",
    "    raise Exception(\"can't sample\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\r\n",
    "#scenario 1: policy exploring around best arm (3) and then (0) becomes the best\r\n",
    "\r\n",
    "class DiscountedAverage:\r\n",
    "    def __init__(self, tau):\r\n",
    "        self.tau = tau\r\n",
    "        self.sumr = 0\r\n",
    "        self.n = 0\r\n",
    "    \r\n",
    "    def update(self, r):\r\n",
    "        self.sumr = self.tau * self.sumr + r\r\n",
    "        self.n = self.tau * self.n + 1\r\n",
    "    \r\n",
    "    def current(self):\r\n",
    "        return self.sumr / self.n\r\n",
    "\r\n",
    "policy = gen_pmf(4, 0.9, 3)\r\n",
    "\r\n",
    "#change 0 to 0.1 and you'll see that the lb actually shrinks \r\n",
    "log = gen_pmf(4, 0, 3)\r\n",
    "\r\n",
    "p0_reward = [0.1, 0.3, 0.3, 0.4]\r\n",
    "p1_reward = [1, 0.3, 0.3, 0.1]\r\n",
    "\r\n",
    "count = 1000\r\n",
    "def run(policy, eval, r, c):\r\n",
    "    np.random.seed(seed=10)\r\n",
    "    ci = OnlineDRO.OnlineCressieReadLB(alpha=0.05, tau=0.999)\r\n",
    "    avg = DiscountedAverage(tau=0.999)\r\n",
    "    for i in range(c):\r\n",
    "       p_action = sample_custom_pmf(policy)\r\n",
    "       e_action = sample_custom_pmf(eval)\r\n",
    "       \r\n",
    "       w = 1 / policy[p_action]\r\n",
    "       if p_action != e_action:\r\n",
    "           w = 0\r\n",
    "       ci.update(c=1, w=w, r=r[p_action])\r\n",
    "       avg.update(r[p_action])\r\n",
    "       ci.recomputeduals()\r\n",
    "       lb = ci.duals[0][0]\r\n",
    "       m = avg.current()\r\n",
    "       step = count / 10\r\n",
    "       if (i % step) == (step - 1):\r\n",
    "        #    print(f's: {i} policy: {p_action} eval: {e_action} r: {r[p_action]} w:{w} ')\r\n",
    "           print(f'[{i}] lb: {lb} mean: {m}')\r\n",
    "\r\n",
    "\r\n",
    "run(policy, log, p0_reward, count)\r\n",
    "\r\n",
    "10\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[99] lb: 0.16796888339914703 mean: 0.26975835418006716\n",
      "[199] lb: 0 mean: 0.2769446132834465\n",
      "[299] lb: 0.25001547984195366 mean: 0.2760558877450576\n",
      "[399] lb: 0 mean: 0.2821628429496422\n",
      "[499] lb: 0 mean: 0.28758211394319344\n",
      "[599] lb: 0 mean: 0.2863197574109059\n",
      "[699] lb: 0 mean: 0.28768856769275714\n",
      "[799] lb: 0 mean: 0.29084603194487235\n",
      "[899] lb: 0 mean: 0.29148221993670476\n",
      "[999] lb: 0 mean: 0.29030934087612753\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}