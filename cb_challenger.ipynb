{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dro import OnlineDRO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pmf(actions, epsilon, exploit_idx):\n",
    "    pmf = [epsilon / actions] * actions\n",
    "    pmf[exploit_idx] += 1 - epsilon\n",
    "    return pmf\n",
    "\n",
    "\n",
    "def sample_custom_pmf(pmf):\n",
    "    total = sum(pmf)\n",
    "    scale = 1 / total\n",
    "    pmf = [x * scale for x in pmf]\n",
    "    draw = np.random.random()\n",
    "    sum_prob = 0.0\n",
    "    for index, prob in enumerate(pmf):\n",
    "        sum_prob += prob\n",
    "        if(sum_prob > draw):\n",
    "            return index\n",
    "    raise Exception(\"can't sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[99] lb: 0.16796888339914703 mean: 0.26975835418006716\n[199] lb: 0 mean: 0.2769446132834465\n[299] lb: 0.25001547984195366 mean: 0.2760558877450576\n[399] lb: 0 mean: 0.2821628429496422\n[499] lb: 0 mean: 0.28758211394319344\n[599] lb: 0 mean: 0.2863197574109059\n[699] lb: 0 mean: 0.28768856769275714\n[799] lb: 0 mean: 0.29084603194487235\n[899] lb: 0 mean: 0.29148221993670476\n[999] lb: 0 mean: 0.29030934087612753\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\n",
    "#scenario 1: policy exploring around best arm (3) and then (0) becomes the best\n",
    "\n",
    "class DiscountedAverage:\n",
    "    def __init__(self, tau):\n",
    "        self.tau = tau\n",
    "        self.sumr = 0\n",
    "        self.n = 0\n",
    "    \n",
    "    def update(self, r):\n",
    "        self.sumr = self.tau * self.sumr + r\n",
    "        self.n = self.tau * self.n + 1\n",
    "    \n",
    "    def current(self):\n",
    "        return self.sumr / self.n\n",
    "\n",
    "# policy = gen_pmf(4, 0.2, 3)\n",
    "policy = gen_pmf(4, 0.9, 3)\n",
    "log = gen_pmf(4, 0, 3)\n",
    "\n",
    "p0_reward = [0.1, 0.3, 0.3, 0.4]\n",
    "p1_reward = [1, 0.3, 0.3, 0.1]\n",
    "\n",
    "count = 1000\n",
    "def run(policy, eval, r, c):\n",
    "    np.random.seed(seed=10)\n",
    "    ci = OnlineDRO.OnlineCressieReadLB(alpha=0.05, tau=0.999)\n",
    "    avg = DiscountedAverage(tau=0.999)\n",
    "    for i in range(c):\n",
    "       p_action = sample_custom_pmf(policy)\n",
    "       e_action = sample_custom_pmf(eval)\n",
    "       \n",
    "       w = 1 / policy[p_action]\n",
    "       if p_action != e_action:\n",
    "           w = 0\n",
    "       ci.update(c=1, w=w, r=r[p_action])\n",
    "       avg.update(r[p_action])\n",
    "       ci.recomputeduals()\n",
    "       lb = ci.duals[0][0]\n",
    "       m = avg.current()\n",
    "       step = count / 10\n",
    "       if (i % step) == (step - 1):\n",
    "        #    print(f's: {i} policy: {p_action} eval: {e_action} r: {r[p_action]} w:{w} ')\n",
    "           print(f'[{i}] lb: {lb} mean: {m}')\n",
    "\n",
    "\n",
    "run(policy, log, p0_reward, count)\n",
    "\n",
    "10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}